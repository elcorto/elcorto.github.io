
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Methods &#8212; imagecluster  documentation</title>
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Usage" href="usage.html" />
    <link rel="prev" title="&lt;no title&gt;" href="index.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../index.html">
    <img class="logo" src="../_static/dendrogram.png" alt="Logo"/>
    
    <h1 class="logo logo-name">imagecluster</h1>
    
  </a>
</p>






<p>
<iframe src="https://ghbtns.com/github-btn.html?user=elcorto&repo=imagecluster&type=watch&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Methods</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#representation-of-image-content-fingerprints">Representation of image content: fingerprints</a></li>
<li class="toctree-l2"><a class="reference internal" href="#content-and-time-distance">Content and time distance</a></li>
<li class="toctree-l2"><a class="reference internal" href="#clustering-and-similarity-index">Clustering and similarity index</a></li>
<li class="toctree-l2"><a class="reference internal" href="#quality-of-clustering-parameters-to-tune">Quality of clustering &amp; parameters to tune</a></li>
<li class="toctree-l2"><a class="reference internal" href="#performance">Performance</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="stuff/index.html">Install</a></li>
<li class="toctree-l1"><a class="reference internal" href="stuff/index.html#contributions">Contributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="stuff/index.html#related-projects">Related projects</a></li>
<li class="toctree-l1"><a class="reference internal" href="stuff/index.html#tests">Tests</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../generated/api/index.html">API Reference</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="index.html">&lt;no title&gt;</a><ul>
      <li>Previous: <a href="index.html" title="previous chapter">&lt;no title&gt;</a></li>
      <li>Next: <a href="usage.html" title="next chapter">Usage</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="methods">
<span id="id1"></span><h1>Methods<a class="headerlink" href="#methods" title="Permalink to this headline">¶</a></h1>
<div class="section" id="representation-of-image-content-fingerprints">
<h2>Representation of image content: fingerprints<a class="headerlink" href="#representation-of-image-content-fingerprints" title="Permalink to this headline">¶</a></h2>
<p>The task of fingerprints (feature vectors) is to represent an image’s
content (mountains, car, kitchen, person, …). Deep convolutional neural
networks trained on many different images have developed an internal
representation of objects in higher layers, which we use for that purpose.</p>
<p>To this end, we use a pre-trained NN (<a class="reference external" href="https://arxiv.org/abs/1409.1556">VGG16</a> as implemented by <a class="reference external" href="https://keras.io">Keras</a>). The
weights will be downloaded <em>once</em> by Keras automatically upon first import and
placed into <code class="docutils literal notranslate"><span class="pre">~/.keras/models/</span></code>. The network was trained on <a class="reference external" href="http://www.image-net.org/">ImageNet</a> and is
able to categorize images into 1000 classes (the last layer has 1000 nodes). We
use (<a class="reference external" href="https://github.com/alexcnwy">thanks for the hint!</a>) the activations of the second to last
fully connected layer (‘fc2’, 4096 nodes) as image fingerprints (numpy 1d array
of shape <code class="docutils literal notranslate"><span class="pre">(4096,)</span></code>) by default.</p>
</div>
<div class="section" id="content-and-time-distance">
<span id="time-scaling"></span><h2>Content and time distance<a class="headerlink" href="#content-and-time-distance" title="Permalink to this headline">¶</a></h2>
<p>Image fingerprints represent content. Clustering based on content ignores time
correlations. Say we have two images of some object that look similar. Thus
their fingerprints are similar (have small distance in feature space) and so
they will
be put into the same cluster. However, they might be in fact pictures of
different objects, taken at different times – which is our original holiday
image use case (e.g. two images of a church from different cities, taken on
separate trips). In this case, we want the images to end up in different
clusters. We have a feature to mix content distance <span class="math notranslate nohighlight">\(d_c\)</span> (from
fingerprints) and time distance <span class="math notranslate nohighlight">\(d_t\)</span> (from timestamps or EXIF tags) such
that</p>
<div class="math notranslate nohighlight">
\[d = \alpha\,d_t + (1 - \alpha)\,d_c\:.\]</div>
<p>One can thus do pure content-based clustering (<span class="math notranslate nohighlight">\(\alpha=0\)</span>) or pure time-based
(<span class="math notranslate nohighlight">\(\alpha=1\)</span>). The effect of the mixing is that fingerprint points representing
content get pushed further apart when the corresponding images’ time distance
is large. That way, we achieve a transparent addition of time information w/o
changing the clustering method. See <a class="reference internal" href="../generated/api/imagecluster.calc.cluster.html#imagecluster.calc.cluster" title="imagecluster.calc.cluster"><code class="xref py py-func docutils literal notranslate"><span class="pre">cluster()</span></code></a>’s
<code class="docutils literal notranslate"><span class="pre">alpha</span></code> and <code class="docutils literal notranslate"><span class="pre">timestamps</span></code> parameters.</p>
</div>
<div class="section" id="clustering-and-similarity-index">
<span id="cluster-sim-index"></span><h2>Clustering and similarity index<a class="headerlink" href="#clustering-and-similarity-index" title="Permalink to this headline">¶</a></h2>
<p>We use <a class="reference external" href="https://en.wikipedia.org/wiki/Hierarchical_clustering">hierarchical clustering</a> (<a class="reference internal" href="../generated/api/imagecluster.calc.cluster.html#imagecluster.calc.cluster" title="imagecluster.calc.cluster"><code class="xref py py-func docutils literal notranslate"><span class="pre">cluster()</span></code></a>),
which compares the image fingerprints (4096-dim vectors, possibly scaled by
time distance) using a distance metric and produces a <a class="reference external" href="https://en.wikipedia.org/wiki/Dendrogram">dendrogram</a>
as an intermediate result. This shows how the images can be grouped together
depending on their similarity (y-axis).</p>
<img alt="../_images/dendrogram.png" src="../_images/dendrogram.png" />
<p>One can now cut through the dendrogram tree at a certain height (<code class="docutils literal notranslate"><span class="pre">sim</span></code>
parameter 0…1, y-axis) to create clusters of images with that level of
similarity. <code class="docutils literal notranslate"><span class="pre">sim=0</span></code> is the root of the dendrogram (top in the plot) where
there is only one node (= all images in one cluster). <code class="docutils literal notranslate"><span class="pre">sim=1</span></code> is equal to the
end of the dendrogram tree (bottom in the plot), where each image is its own
cluster. By varying the index between 0 and 1, we thus increase the number of
clusters from 1 to the number of images. However, note that we only report
clusters with at least 2 images, such that <code class="docutils literal notranslate"><span class="pre">sim=1</span></code> will in fact produce no
results at all (unless there are completely identical images).</p>
</div>
<div class="section" id="quality-of-clustering-parameters-to-tune">
<span id="cluster-params"></span><h2>Quality of clustering &amp; parameters to tune<a class="headerlink" href="#quality-of-clustering-parameters-to-tune" title="Permalink to this headline">¶</a></h2>
<p>Apart from the obvious <code class="docutils literal notranslate"><span class="pre">sim</span></code> and <code class="docutils literal notranslate"><span class="pre">alpha</span></code> parameters, the parameters of
the clustering method itself are worth tuning. ATM, we expose only some in
<a class="reference internal" href="../generated/api/imagecluster.calc.cluster.html#imagecluster.calc.cluster" title="imagecluster.calc.cluster"><code class="xref py py-func docutils literal notranslate"><span class="pre">cluster()</span></code></a>. We tested several distance metrics and
linkage methods, but this could nevertheless use a more elaborate evaluation.
See <a class="reference internal" href="../generated/api/imagecluster.calc.cluster.html#imagecluster.calc.cluster" title="imagecluster.calc.cluster"><code class="xref py py-func docutils literal notranslate"><span class="pre">cluster()</span></code></a> for <cite>method</cite>, <cite>metric</cite> and <cite>criterion</cite>
and the scipy functions called. If you do this and find settings which perform
much better – PRs welcome!</p>
<p>Additionally, some other implementations do not use any of the inner fully
connected layers as features, but instead the output of the last pooling layer
(layer ‘flatten’ in Keras’ VGG16). We tested that briefly (see
<code class="docutils literal notranslate"><span class="pre">calc.get_model(...</span> <span class="pre">layer='fc2')</span></code>) and found our default ‘fc2’ to perform
well enough. ‘fc1’ performs almost the same, while ‘flatten’ seems to do worse.
But again, a quantitative analysis is in order.</p>
<p>PCA: Because of the <a class="reference external" href="https://en.wikipedia.org/wiki/Curse_of_dimensionality">Curse of dimensionality</a>, it may be helpful to
perform a PCA on the fingerprints before clustering to reduce the feature
vector dimensions to, say, a few 100, thus making the distance metrics used in
clustering more effective. However, our tests so far show no substantial change
in clustering results, in accordance to what <a class="reference external" href="https://github.com/beleidy/unsupervised-image-clustering">others have found</a>. See <code class="docutils literal notranslate"><span class="pre">examples/example_api.py</span></code> and
<a class="reference internal" href="../generated/api/imagecluster.calc.pca.html#imagecluster.calc.pca" title="imagecluster.calc.pca"><code class="xref py py-func docutils literal notranslate"><span class="pre">pca()</span></code></a>.</p>
</div>
<div class="section" id="performance">
<h2>Performance<a class="headerlink" href="#performance" title="Permalink to this headline">¶</a></h2>
<p>The bottleneck in all calculations is <a class="reference internal" href="../generated/api/imagecluster.calc.fingerprints.html#imagecluster.calc.fingerprints" title="imagecluster.calc.fingerprints"><code class="xref py py-func docutils literal notranslate"><span class="pre">fingerprints()</span></code></a>,
all other operations have negligible relative cost. Especially clustering is
very fast.</p>
<p>Fingerprints calculation puts each image thru the TensorFlow NN model (VGG16).
Due to technical foo (see <a class="reference internal" href="../generated/api/calc.html#module-imagecluster.calc" title="imagecluster.calc"><code class="xref py py-mod docutils literal notranslate"><span class="pre">calc</span></code></a> for details, PRs welcome!)
we cannot paralellize over images using <code class="docutils literal notranslate"><span class="pre">multiprocessing</span></code>. Instead we do a
serial loop over images and leverage TensorFlow’s threading which which is on
by default. On low core counts, this does indeed scale OK.</p>
</div>
</div>


          </div>
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &copy;2019, Steve Schmerler.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.8.4</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.8</a>
      
      |
      <a href="../_sources/written/methods.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>